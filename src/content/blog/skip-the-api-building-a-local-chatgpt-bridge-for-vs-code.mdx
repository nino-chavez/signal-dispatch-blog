---
title: "Skip the API: Building a Local ChatGPT Bridge for VS Code"
slug: "skip-the-api-building-a-local-chatgpt-bridge-for-vs-code"
publishedAt: "2025-07-31T11:47:37.000Z"
updatedAt: "2025-07-31T11:47:37.000Z"
author: "Nino Chavez"
status: "published"
excerpt: "Can you skip the API and wire ChatGPT directly into VS Code? Turns out, yes â€” with a little browser magic. This post breaks down how I thought about building a local-first bridge that replaces Kilo and avoids token costs, all powered by curiosity and a builderâ€™s mindset."
featureImage: "/content/images/2025/07/12326509-scott-adams-graphic-adventure-4-voodoo-castle-apple-ii-making-ma.png"
tags:
  - ai
  - meta-on-meta
  - strategy
  - workflow
category: "AI & Automation"
seo:
  metaTitle: "Skip the API: Building a Local ChatGPT Bridge for VS Code"
  metaDescription: "Can you skip the API and wire ChatGPT directly into VS Code? Turns out, yes â€” with a little browser magic. This post breaks down how I thought about building a local-first bridge that replaces Kilo and avoids token costs, all powered by curiosity and a builderâ€™s mindset."
  ogImage: "/content/images/2025/07/12326509-scott-adams-graphic-adventure-4-voodoo-castle-apple-ii-making-ma.png"
---

**What if you could connect ChatGPT directly to your editor â€” no API key, no per-token billing â€” and still get structured code completions?**

This started as a late-night thought experiment. But like most things in my workflow, it quickly turned into a buildable idea.

The PremiseI was already using ChatGPT Plus. I was also using tools like Kilo, Claude, and other AI dev agents to refactor code, automate diffs, and ship faster.

But I started wondering:

> *Why am I paying per-token for OpenAIâ€™s API when Iâ€™m already paying for unlimited GPT-4o inside the ChatGPT UI?*

More importantly:

> *Can I just build a VS Code plugin that pipes code in and out of a ChatGPT browser session?*

Short answer: **Yes. You can.**
Long answer: Itâ€™s not elegant â€” but it works.

Prompt Evolution (Real Chat History)I started with:

> *â€œHow feasible would it be to write a Viscose plugin that connects to you via API so I can replace Kilo?â€*

ChatGPT: Totally feasible. Use the OpenAI API, pass in file context, return completions or diffs, inject into editor. Rebuild Kiloâ€™s core logic yourself.

Then I refined:

> *â€œPrompt yourself to ask my question better. In my tone.â€*

ChatGPT rewrote it:

> *â€œHow hard would it be to drop Kilo and just run you through a custom VS Code plugin instead? Full replacement. Can I wire you up and ditch the rest?â€*

Finally, the real unlock:

> *â€œTo avoid API token costs, can I build a plugin that uses a browser for I/O, since I already pay for ChatGPT Plus?â€*

And ChatGPT confirmed:

> Yes. You can build a VS Code plugin that:Sends code to ChatGPT via clipboard or embedded WebViewReceives output and injects it back into the editorBypasses the API completely

What This Actually Looks LikeThere are a few implementation paths:

Option 1: Clipboard Sync (Manual Bridge)- Select code in VS Code
- Hotkey to copy â†’ auto-paste into ChatGPT tab
- Copy reply â†’ paste back into file
- Wrap with custom commands/macros for speed

Option 2: WebView + DOM Sync (Semi-Automated)- Create a VS Code extension with a ChatGPT WebView panel
- Hook into the DOM of the embedded session
- Programmatically send and receive text
- No need for API â€” just browser automation

Option 3: Puppeteer Bridge (Full Automation)- Launch Chrome with Puppeteer
- Log in to ChatGPT
- Inject prompts, wait for DOM response
- Pipe result into VS Code

This oneâ€™s the most brittle (ChatGPT DOM changes often), but itâ€™s surprisingly robust for light workflows.

Tradeoffs

FeatureBrowser BridgeOpenAI APICostâœ… Included w/ PlusðŸ’¸ Pay per tokenControlâœ… Full prompt designâœ… Full prompt designStabilityâš ï¸ Subject to UI changesâœ… Stable API contractPerformanceðŸŸ¡ Slowerâœ… FastMemory / ThreadsðŸŸ¡ Manual managementðŸŸ¡ Manual management

Why This MattersIâ€™m not doing this to be clever. Iâ€™m doing it because itâ€™s the kind of move that compounds over time.

Owning your interface with the AI layer gives you:

- Control over **prompt engineering**
- Customizable **task types and code styles**
- **No vendor lock-in** or per-feature paywalls
- A faster loop between idea â†’ implementation â†’ iteration

More than that â€” this is how I think now.
Years of system architecture and even more years of playing *Voodoo Castle* and *Pirate's Cove* text-adventure games trained me to ask:

> *â€œWhat if this works?â€*

And these days, more often than not â€”
**it does.**

Coming Soon: `gpt-bridge`Iâ€™m turning this into a small open-source scaffold (eventually; probably):

> **`gpt-bridge`** â€” a local-first VS Code extension that connects to your running ChatGPT tab via clipboard, WebView, or local socket.

Itâ€™ll be dead simple:

- Select code â†’ run task â†’ receive structured completion
- All through your browser session

If you want in early, DM me or drop your email.
And if youâ€™re building weird AI tooling â€” letâ€™s talk.

ðŸ§  *Signal Dispatch* is where I write about systems, AI workflows, and how software is changing.
ðŸ“¡ Subscribe if you're into technical curiosity with just enough reflection to keep it human.
