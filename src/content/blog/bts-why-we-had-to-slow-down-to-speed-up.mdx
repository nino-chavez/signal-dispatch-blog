---
title: "Behind the Scenes: Why We Had to Slow Down to Speed Up"
slug: "bts-why-we-had-to-slow-down-to-speed-up"
publishedAt: "2025-08-03T01:58:33.000Z"
updatedAt: "2025-08-03T01:58:33.000Z"
author: "Nino Chavez"
status: "published"
excerpt: "A simple bulk upload broke — 22 teams skipped, 0 created. The fix seemed easy. AI suggested patching the frontend. But that would’ve locked in a broken contract. Here's how we slowed down, re-architected the system, and avoided weeks of silent tech debt and wasted tokens."
featureImage: "/content/images/2025/08/photo-1706618184116-425c7aaec79c.jpeg"
tags:
  - ai-workflows
category: "AI & Automation"
seo:
  metaTitle: "Behind the Scenes: Why We Had to Slow Down to Speed Up"
  metaDescription: "A simple bulk upload broke — 22 teams skipped, 0 created. The fix seemed easy. AI suggested patching the frontend. But that would’ve locked in a broken contract. Here's how we slowed down, re-architected the system, and avoided weeks of silent tech debt and wasted tokens."
  ogImage: "/content/images/2025/08/photo-1706618184116-425c7aaec79c.jpeg"
---
> “22 Skipped. 0 Created.”
> “Team name is required and must be a non-empty string.”

This is what greeted us during a routine bulk upload for a volleyball tournament.

At first glance, it looked like a basic validation error. The frontend was trying to upload teams with no names. The backend was doing its job — rejecting any entry without a `team_name`.

But that’s not the full story.

This was a **small architecture bug that scaled quickly**, compounded by a **misaligned AI response** that nearly patched the problem in the worst way: by hardcoding logic where it didn’t belong. It’s a perfect example of what breaks when you move too fast, rely on brittle assumptions, and don’t pause to think systemically.

Let’s walk through it.

🧃 The Setup: “Grass Volleyball” FormatWe were uploading team rosters using a format common to grass volleyball tournaments:

```
Charlie Podgorny, Nate Meyer, Peter Zurawski	1  
Grant Veldman, Will Mensching, Everett Haynes	2

```

No explicit team names — just player names and seeds.

On the frontend, the CSV parser **detected** this format and automatically created `TeamInput` objects like:

```json
{
  team_name: '', // Will be generated from captain's last name
  players: 'Charlie Podgorny, Nate Meyer, Peter Zurawski',
  seed: 1
}

```

There was even a code comment explaining the plan:

```
// team_name: '', // Will be generated from captain's last name

```

The problem? That logic was never implemented.

🚨 The BreakdownWhen the upload hit the backend, our validation function looked like this:

```typescript
if (!team_name || team_name.trim().length === 0) {
  throw new ValidationError("Team name is required");
}

```

And so: **every team was skipped** with "Team name is required" errors.

We didn’t have a bug.
We had a breakdown in **assumptions**.

🤖 How the AI Almost Made It WorseHere’s the original prompt I gave the AI:

> “We should produce as much of what the backend expects on the frontend.
> But don’t you agree that general engineering principles say **deriving specific data from general input should happen on the backend**?
> Classic example: different frontend channels besides the website will force duplication if we don’t centralize it.”

And this was the AI’s first response:

> “Let’s fix the frontend CSV parser.
> Extract the captain’s last name and generate a team name like ‘Zurawski Team’.
> Add fallback logic to handle duplicates.”

It was trying to help — but in the **wrong layer**.
Patching the frontend to generate team names was faster…
But it **cemented the broken contract** between systems.

I pushed back.

🧠 The RealizationI proposed a redesign:

> “Should we separate the bulk upload into two steps — Parse and Submit?
> Visually, this lets users preview and verify parsed data before it goes into the DB.
> Programmatically, it gives the backend a clear contract: ‘Here’s the general data. You derive the specifics.’
> As long as we have correct defaults and fallback logic, the backend should be responsible for generating the DB-safe values.”

This time, the AI aligned.

> ✅ “You raise excellent architectural points.
> Separation of concerns. Single source of truth. Avoiding duplication.
> Let’s implement a Parse → Submit flow:**Frontend**: parses raw CSV to `ParsedTeamInput[]`, shows editable preview**Backend**: derives team names, applies fallbacks, validates, inserts**UX**: gives the human a chance to correct edge cases before they go live”

That was the unlock.

🧱 The New Architecture (What We Did Instead)Step 1: Parse- Frontend reads raw data, builds a minimal object with:`players`
- `seed`
- optional hints (division, captain, etc.)

**No business logic**Displays a preview table with auto-generated team namesStep 2: Submit- Backend receives minimal input and:Derives `team_name` from the captain’s last name
- Applies fallbacks (e.g., "Team 1", "Team 2")
- Validates full domain logic
- Handles DB insertion and returns result breakdown

✍️ Why This MattersThis wasn't just a logic bug. It was a **design trap**:

- The frontend assumed the backend would fix things
- The backend assumed the frontend would never send invalid data
- The AI assumed the fastest patch was the right one

No one paused to ask: *Should the frontend even be generating this?*

🔄 When Speed Hurts, Slow DownThis is what it means to **slow down to speed up**:

- To *not* patch the frontend for a backend failure
- To *not* accept broken contracts between layers
- To *not* let your AI assistant “move fast” at the cost of long-term clarity

This was a real bug that exposed a brittle system boundary — and it almost got worse before we took a beat and redesigned it.

Would an agentic AI have caught this?
Maybe — if it had the training of a senior engineer.
But the real fix came from a human noticing the friction and **zooming out**.

💥 The Real CostThis wasn’t just a missed detail — it was almost a wasted sprint.

If I hadn’t stepped back to notice the architectural drift,
I would’ve wasted **two more weeks**,
shipping a patch that silently **duplicated logic**,
broke the contract across clients,
and **burned hundreds of dollars in AI tokens**.

AI will move fast.
But someone still has to *steer the system*.
